import requests
import os
import urllib.parse

# --- 配置区 ---
SOURCES_TO_CONVERT = [
    "https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/SpywareFilter/sections/tracking_servers.txt",
    "https://raw.githubusercontent.com/privacy-protection-tools/anti-ad/master/anti-ad-adguard.txt",
    "https://raw.githubusercontent.com/damengzhu/banad/main/jiekouAD.txt",
    "http://rssv.cn/adguard/api.php?type=black"  # 需要使用user-agent的api源
]
# --- 修改点：更新输出文件的路径 ---
OUTPUT_FILE = "Loon/generated/converted-ad-rules.list"


def main():
    print("--- Starting Conversion Process ---")
    all_rules = set()

    # 定义特殊的请求头，模拟AdGuard客户端
    adguard_headers = {'User-Agent': 'AdGuard'}

    for url in SOURCES_TO_CONVERT:
        try:
            # 判断是否为需要通过代理桥访问的链接
            if "rssv.cn" in url:
                print(f"-> Detected special source: {url}")
                # 使用 allorigins.win 作为代理桥来抓取内容
                encoded_url = urllib.parse.quote_plus(url)
                bridge_url = f"https://api.allorigins.win/raw?url={encoded_url}"
                print(f"--> Using bridge to fetch: {bridge_url}")

                # 请求代理桥，并延长超时时间
                response = requests.get(bridge_url, headers=adguard_headers, timeout=120)
            else:
                # 对其他普通链接使用标准请求
                response = requests.get(url, timeout=60)

            response.raise_for_status()
            print(f"✅ Fetched {url}")
            lines = response.text.split('\n')

            for line in lines:
                # 跳过注释和空行
                line = line.split('#')[0].split('!')[0].strip()
                if not line or line.startswith(('[', '/')):
                    continue

                # --- 统一处理所有已知格式 ---
                domain = ""
                # 格式 1: Adblock Plus (||example.com^)
                if line.startswith('||') and line.endswith('^'):
                    domain = line[2:-1]
                # 格式 2: rssv.cn 的格式 (example.com^)
                elif line.endswith('^'):
                    domain = line[:-1]
                # 格式 3: 已有的Loon/QX格式
                elif ',' in line and line.upper().startswith('DOMAIN'):
                    parts = line.split(',')
                    rule = f"{parts[0].strip().upper()},{parts[1].strip().lower()}"
                    all_rules.add(rule)
                    continue
                # 格式 4: Hosts 格式
                elif line.startswith(('0.0.0.0', '127.0.0.1')):
                    parts = line.split()
                    if len(parts) >= 2:
                        domain = parts[1]
                    else:
                        continue
                # 格式 5: 纯域名
                else:
                    domain = line

                # 为提取出的域名生成统一的Loon规则
                if domain:
                    if ' ' in domain or '/' in domain or '*' in domain:
                        continue
                    rule = f"DOMAIN-SUFFIX,{domain.strip().lower()}"
                    all_rules.add(rule)

        except requests.RequestException as e:
            print(f"❌ Error fetching {url}: {e}")

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(f"# Auto-generated by converter.py\n")
        f.write(f"# Total unique rules: {len(all_rules)}\n\n")
        for rule in sorted(list(all_rules)):
            f.write(f"{rule}\n")
    print(f"🎉 Generated {OUTPUT_FILE} with {len(all_rules)} rules.")


if __name__ == "__main__":
    main()