import requests
import os
import urllib.parse

# --- é…ç½®åŒº ---
SOURCES_TO_CONVERT = [
    "https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/SpywareFilter/sections/tracking_servers.txt",
    "https://raw.githubusercontent.com/privacy-protection-tools/anti-ad/master/anti-ad-adguard.txt",
    "https://raw.githubusercontent.com/damengzhu/banad/main/jiekouAD.txt",
    "http://rssv.cn/adguard/api.php?type=black"  # éœ€è¦ä½¿ç”¨user-agentçš„apiæº
]
# --- ä¿®æ”¹ç‚¹ï¼šæ›´æ–°è¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ ---
OUTPUT_FILE = "Loon/generated/converted-ad-rules.list"


def main():
    print("--- Starting Conversion Process ---")
    all_rules = set()

    # å®šä¹‰ç‰¹æ®Šçš„è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸAdGuardå®¢æˆ·ç«¯
    adguard_headers = {'User-Agent': 'AdGuard'}

    for url in SOURCES_TO_CONVERT:
        try:
            # åˆ¤æ–­æ˜¯å¦ä¸ºéœ€è¦é€šè¿‡ä»£ç†æ¡¥è®¿é—®çš„é“¾æ¥
            if "rssv.cn" in url:
                print(f"-> Detected special source: {url}")
                # ä½¿ç”¨ allorigins.win ä½œä¸ºä»£ç†æ¡¥æ¥æŠ“å–å†…å®¹
                encoded_url = urllib.parse.quote_plus(url)
                bridge_url = f"https://api.allorigins.win/raw?url={encoded_url}"
                print(f"--> Using bridge to fetch: {bridge_url}")

                # è¯·æ±‚ä»£ç†æ¡¥ï¼Œå¹¶å»¶é•¿è¶…æ—¶æ—¶é—´
                response = requests.get(bridge_url, headers=adguard_headers, timeout=120)
            else:
                # å¯¹å…¶ä»–æ™®é€šé“¾æ¥ä½¿ç”¨æ ‡å‡†è¯·æ±‚
                response = requests.get(url, timeout=60)

            response.raise_for_status()
            print(f"âœ… Fetched {url}")
            lines = response.text.split('\n')

            for line in lines:
                # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
                line = line.split('#')[0].split('!')[0].strip()
                if not line or line.startswith(('[', '/')):
                    continue

                # --- ç»Ÿä¸€å¤„ç†æ‰€æœ‰å·²çŸ¥æ ¼å¼ ---
                domain = ""
                # æ ¼å¼ 1: Adblock Plus (||example.com^)
                if line.startswith('||') and line.endswith('^'):
                    domain = line[2:-1]
                # æ ¼å¼ 2: rssv.cn çš„æ ¼å¼ (example.com^)
                elif line.endswith('^'):
                    domain = line[:-1]
                # æ ¼å¼ 3: å·²æœ‰çš„Loon/QXæ ¼å¼
                elif ',' in line and line.upper().startswith('DOMAIN'):
                    parts = line.split(',')
                    rule = f"{parts[0].strip().upper()},{parts[1].strip().lower()}"
                    all_rules.add(rule)
                    continue
                # æ ¼å¼ 4: Hosts æ ¼å¼
                elif line.startswith(('0.0.0.0', '127.0.0.1')):
                    parts = line.split()
                    if len(parts) >= 2:
                        domain = parts[1]
                    else:
                        continue
                # æ ¼å¼ 5: çº¯åŸŸå
                else:
                    domain = line

                # ä¸ºæå–å‡ºçš„åŸŸåç”Ÿæˆç»Ÿä¸€çš„Loonè§„åˆ™
                if domain:
                    if ' ' in domain or '/' in domain or '*' in domain:
                        continue
                    rule = f"DOMAIN-SUFFIX,{domain.strip().lower()}"
                    all_rules.add(rule)

        except requests.RequestException as e:
            print(f"âŒ Error fetching {url}: {e}")

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(f"# Auto-generated by converter.py\n")
        f.write(f"# Total unique rules: {len(all_rules)}\n\n")
        for rule in sorted(list(all_rules)):
            f.write(f"{rule}\n")
    print(f"ğŸ‰ Generated {OUTPUT_FILE} with {len(all_rules)} rules.")


if __name__ == "__main__":
    main()